<project_specification>
  <project_name>Heystack - File Analysis Platform on Spernakit</project_name>

  <overview>
    Heystack is a sophisticated file analysis and monitoring web application that provides
    intelligent file system monitoring, content analysis, and rich visual insights. This
    specification describes a Spernakit-based implementation of Heystack that preserves the
    existing product goals while replatforming onto the SPERN stack (SQLite, Prisma,
    Express, React, Node.js on Bun) with JSON-driven configuration.

    The application must:

    - Continuously monitor configured file system paths with recursive traversal and
      metadata tracking
    - Detect and record file changes (new, modified, deleted, or quarantined) with
      detailed scan history
    - Perform advanced content analysis (text extraction, summarization, categorization,
      tagging, duplicate detection) at scale
    - Provide powerful search, filtering, and discovery across files, summaries,
      categories, tags, and scan results
    - Visualize file relationships, activity timelines, category distributions, and
      tag clouds using D3-powered dashboards
    - Offer configurable automation and scheduling for scans with resource management,
      progress tracking, and retry behavior
    - Support compliance and auditing use cases through comprehensive history,
      alerting, and exportable reports

    The target audience includes system administrators, content managers, data analysts,
    file system auditors, and knowledge management teams who need deep visibility into
    large file systems. The UI should present a modern, responsive dashboard experience
    (dark/light modes, Flowbite/DaisyUI patterns) while the backend provides secure,
    observable, and performant services aligned with Spernakit architecture.
  </overview>

  <technology_stack>
    <api_key>
      You can use an API key located at /tmp/api-key for testing. You will not be allowed to
      read this file in the repo, but you can reference it in code (e.g., via config paths).
    </api_key>

    <spernakit_architecture>
      <core_stack>SPERN (SQLite, Prisma, Express, React, Node.js)</core_stack>
      <runtime>Bun runtime for both frontend and backend services</runtime>
      <package_manager>Bun for dependency management and scripts</package_manager>
      <monorepo_structure>Workspace architecture with frontend/backend separation</monorepo_structure>
      <configuration>JSON-driven config via config/spernakit.json (no implicit .env loading)</configuration>
      <database>
        SQLite in WAL mode for default deployments, with Prisma schema compatible with
        PostgreSQL for future upgrades.
      </database>
      <process_model>
        Single monorepo with:
        - /frontend (React + Vite)
        - /backend (Express + Prisma)
        - Shared type definitions and API contracts
      </process_model>
    </spernakit_architecture>

    <frontend>
      <framework>React 19 with Vite 5</framework>
      <styling>Tailwind CSS with DaisyUI component library</styling>
      <state_management>
        - TanStack Query (React Query) for server state
        - React Context + hooks for app-level state (auth, theme, layout, project)
      </state_management>
      <routing>React Router with ProtectedRoute components for RBAC-aware routing</routing>
      <markdown>React Markdown (and plugins) for message + artifact rendering</markdown>
      <code_highlighting>
        Syntax highlighting for code blocks using a Monaco-compatible theme with copy buttons
        and optional language selector.
      </code_highlighting>
      <ui_components>
        Primary: DaisyUI components
        Secondary patterns: Flowbite-inspired cards, dashboards, and status widgets adapted
        to DaisyUI themes and Spernakit style rules.
      </ui_components>
      <visualization>
        D3.js v7 for advanced data visualization:
        - File relationship graphs
        - Activity timelines
        - Category/tag distributions
        - Search/usage analytics
      </visualization>
      <file_insights_ui>
        Heystack-style panels integrated into the main layout:
        - Scan activity stream and progress indicators
        - Tag clouds and category breakdowns
        - Relationship graphs linking files, tags, and conversations
        - Drill-down detail views for individual files or clusters
      </file_insights_ui>
      <progressive_enhancements>
        HTMX/_hyperscript-inspired micro-interactions implemented as React hooks and
        lightweight helper utilities for:
        - Scheduler controls (start/pause/resume/cancel)
        - Inline filters and quick actions on lists
        - Optimistic UI updates on scan operations
      </progressive_enhancements>
      <port>Only launch on port {frontend_port} (default: 3330)</port>
    </frontend>

    <backend>
      <runtime>Node.js with Express 5, running on Bun</runtime>
      <database>SQLite with Prisma ORM (PostgreSQL-compatible schema)</database>
      <orm>Prisma ORM with automated migrations, type-safe client, and Studio</orm>
      <api_integration>Claude API via Anthropic SDK for file/content analysis (summarization, tagging, explanation) and tools that operate over Heystack scan results</api_integration>
      <streaming>
        - Server-Sent Events (SSE) for streaming assistant responses related to file analysis and investigations
        - WebSocket channels for notifications, scan progress, and dashboards
      </streaming>
      <authentication>
        JWT with HTTP-only cookies and a 5-tier RBAC system:
        - SYSOP > ADMIN > MANAGER > OPERATOR > VIEWER (hierarchical inheritance)
      </authentication>
      <security>
        - CSP headers, CORS allowlists per environment
        - Rate limiting (per-IP and per-endpoint tiers)
        - Input validation with Joi or Zod schemas
        - Comprehensive audit logging of security-sensitive actions
      </security>
      <file_scanner_service>
        Node worker (or background service) with optional PowerShell child-process bridge
        that reuses Heystack scanner modules for:
        - Recursive directory traversal with metadata capture
        - Change detection (new/modified/deleted files)
        - Checksum generation (MD5/SHA-256) for integrity and deduplication
        - Binary vs text detection and safe content handling
        - Progress reporting for long-running scans (via events/WS)
        - Partial scan resumption after failures or restarts
        - Scale target: 1M+ files per workspace with efficient indexing
      </file_scanner_service>
      <content_analysis_pipeline>
        Background jobs orchestrated via scheduler queues that perform:
        - Text extraction (per file type) into normalized content fields
        - Summarization using Claude (configurable models + cost constraints)
        - Categorization with confidence scoring (0-1 scale)
        - Dynamic tag generation based on content patterns, metadata, and history
        - File relationship detection (similarity, shared tags, paths, and usage)
        - Duplicate and near-duplicate detection via checksums + heuristics
      </content_analysis_pipeline>
      <scheduler_engine>
        - Cron-expression and calendar-based schedules
        - Timezone-aware execution with DST-safe handling
        - Pause/resume, cancel, and manual trigger support
        - Resource throttling (CPU, memory, IO limits) per job or schedule group
        - Scan queues for concurrent operations with fairness policies
        - Retry with exponential backoff on failure
        - Persistent schedule definitions in Prisma models (scan_schedules, jobs, runs)
      </scheduler_engine>
      <observability>
        - Structured JSON logging with correlation IDs
        - Health, readiness, and liveness endpoints
        - Prometheus-friendly metrics endpoint (HTTP)
        - Error-rate and latency tracking per route and queue
        - Optional WebSocket stream for real-time activity in admin dashboards
      </observability>
    </backend>

    <communication>
      <api>RESTful endpoints with standardized JSON envelopes and error shapes</api>
      <streaming>SSE for real-time assistant/file-analysis streaming tied to Heystack investigations + WebSocket for notifications</streaming>
      <claude_api>All Claude API calls routed through backend proxy endpoints</claude_api>
      <websocket>
        - Notification channels for conversations, projects, and admin events
        - Real-time updates for file scans, content analysis, and visualization refresh
      </websocket>
      <scanner_events>
        Dedicated channels for:
        - Scan lifecycle events (queued, running, paused, completed, failed)
        - Per-scan progress updates (% complete, files processed, ETA)
        - Anomaly alerts (access denied, corrupt files, unusual growth)
        - Visualization refresh triggers for affected views
      </scanner_events>
      <rate_limiting>
        - Baseline: 60 requests/minute per IP for general APIs
        - Stricter caps for expensive endpoints (scan triggers, mass exports)
        - Configurable per-environment via config/spernakit.json
      </rate_limiting>
      <cors>
        Configurable per environment with explicit allowlists; no wildcard for production.
      </cors>
    </communication>

    <performance_requirements>
      <api_response_time>95% of API requests complete in &lt;= 500ms</api_response_time>
      <database_queries>95% of complex queries complete in &lt;= 100ms</database_queries>
      <ui_rendering>Initial page loads render interactively in &lt;= 200ms on modern hardware</ui_rendering>
      <concurrent_users>Support at least 50 concurrent users per default deployment</concurrent_users>
      <file_system_scale>Handle 1M+ files with responsive queries and scans</file_system_scale>
      <scan_performance>Target average processing rate of 1000 files/minute</scan_performance>
      <search_performance>Search results for 1M files return in &lt;= 500ms (95th percentile)</search_performance>
    </performance_requirements>

    <development_tools>
      <scripts>
        - bun run init: Initialize workspaces, install deps, prepare config
        - bun run dev: Start both frontend and backend
        - bun run dev:backend: Start Express backend only
        - bun run dev:frontend: Start React frontend only
        - bun run build: Build both frontend and backend
        - bun run format: Format code with Prettier
        - bun run lint: Lint code with ESLint
        - bun run db:setup: Generate Prisma client, run migrations, seed data
      </scripts>
      <code_quality>ESLint for linting, Prettier for formatting, TypeScript strict mode</code_quality>
      <database_tools>Prisma Studio for database management and inspection</database_tools>
      <docker>Monolithic Docker image with nginx + supervisord for prod</docker>
      <testing_stack>
        - Vitest / Jest for unit and integration tests
        - Playwright for E2E flows
        - Custom load tests for scan throughput and API latency
        - Pester/PowerShell tests for scanner bridge scripts (if applicable)
      </testing_stack>
      <profiling>
        - Node perf hooks and Bun inspect for backend
        - D3 render and interaction profiling in storybook-like sandboxes
      </profiling>
    </development_tools>

    <platform_requirements>
      <server>
        - Bun 1.1+
        - Node-compatible environment
        - PowerShell Core 7.4+ available on host for scanner bridge
      </server>
      <client>
        - Modern browsers (latest two versions of Chrome, Firefox, Safari, Edge)
        - WebGL + WASM enabled for visualization-heavy views
      </client>
      <database>SQLite 3+ with WAL mode; optional PostgreSQL via Prisma for scale-out</database>
      <os_support>Primary dev target: Windows 11, with Linux/macOS parity via Bun</os_support>
    </platform_requirements>

    <heystack_adapters>
      <visualization_runtime>
        D3.js v7 modules packaged as React components with stable data contracts (graph
        nodes/edges, timeseries, distributions) reused across dashboards.
      </visualization_runtime>
      <flowbite_bridge>
        Shared design token map so Flowbite-style layouts coexist with DaisyUI themes without
        CSS collisions or reset conflicts.
      </flowbite_bridge>
      <scheduler_bridge>
        Reusable scheduler configuration JSON schema used by both chat automations and
        file scans, enabling unified schedule management.
      </scheduler_bridge>
    </heystack_adapters>
  </technology_stack>

  <prerequisites>
    <environment_setup>
      - Application configuration stored in config/spernakit.json (and environment-specific
        variants), including:
        - Server ports
        - Database paths
        - API keys/secret file paths (e.g., /tmp/api-key)
        - Feature-level toggles where appropriate
      - Frontend dependencies installed via `bun install` in /frontend
      - Backend dependencies installed via `bun install` in /backend
      - Database bootstrapped via `bun run db:setup` (generate client, run migrations, seed)
      - Development assumes Bun environment with no implicit .env loading
    </environment_setup>
    <development_commands>
      - bun run init
      - bun run dev
      - bun run dev:backend
      - bun run dev:frontend
      - bun run build
      - bun run format
      - bun run lint
      - bun run db:setup
    </development_commands>
  </prerequisites>

  <core_features>
    <assistant_panel>
      - Heystack assistant panel for asking questions about scanned files, changes, and tags, using a clean, centered layout with familiar message bubbles (inspired by modern tools, not intended as a generic chat clone)
      - Streaming responses with typing indicators and partial message rendering
      - Markdown rendering (lists, headers, tables) and inline images
      - Code blocks with syntax highlighting, language labels, and copy button
      - LaTeX/math equation rendering for technical content
      - Image upload and inline preview in messages (with audit trail)
      - Multi-turn conversational context with correct model parameters
      - Message editing and regeneration (per-message) with history tracking
      - Stop-generation button during streaming
      - Auto-resizing textarea with character count and token estimation
      - Keyboard shortcuts (Enter to send, Shift+Enter for newline)
    </assistant_panel>

    <artifacts>
      - Automatic detection of artifact-style responses (code, diagrams, docs)
      - Side-panel artifact viewer with tabbed layout
      - Code artifact viewer with diffing between versions
      - HTML/SVG live preview
      - React component preview (where safe/practical)
      - Mermaid diagram rendering
      - Text document artifact support with full-screen mode
      - Artifact editing and re-prompting based on current version
      - Download/copy artifact content
      - Artifact versioning and history with audit log entries
    </artifacts>

    <investigation_management>
      - Create, rename, duplicate, and delete (soft-delete) investigation sessions over Heystack file and scan data
      - Sidebar list of investigation sessions with virtual scrolling for large histories
      - Automatic title generation from first exchange (with inline rename)
      - Investigation search by title/content and related file context
      - Pin and archive investigation sessions
      - Folder- and project-based organization
      - Export investigation history (assistant prompts/responses plus key file references) to JSON, Markdown, and PDF
      - Timestamps (created, updated, last accessed)
      - Unread indicators and basic activity markers
      - Full audit trail of investigation-level actions (creation, updates, exports)
    </investigation_management>

    <projects>
      - Create projects to group monitored paths, scan configurations, investigation sessions, artifacts, and knowledge base docs
      - Upload project knowledge base documents with metadata
      - Project-specific custom instructions and defaults
      - RBAC-based project sharing (mock or real, depending on deployment)
      - Project analytics (usage, scan coverage, key tags)
      - Project templates for common use cases
    </projects>

    <model_selection>
      - Model selector with at least these options (names illustrative):
        - Claude Sonnet 4.5 (default)
        - Claude Haiku 4.5
        - Claude Opus 4.1
      - Context window and capability indicators per model
      - Model pricing information (display only, no billing integration)
      - Ability to switch models mid-conversation with clear UX
      - Optional model comparison/help view
    </model_selection>

    <custom_instructions>
      - Global custom instructions per user
      - Project-specific instructions layered on global
      - Conversation-specific system prompts layered on project/global
      - Instruction templates and presets
      - Preview area explaining how instructions will influence responses
    </custom_instructions>

    <settings_preferences>
      - Theme selection (Light, Dark, Auto/system)
      - Font size and message density controls
      - Code theme selection
      - Advanced toggles (show tokens, developer-mode panes, experimental features)
    </settings_preferences>

    <file_monitoring>
      - Configurable root paths and include/exclude patterns
      - Recursive directory traversal with metadata capture
      - Change detection (new/modified/deleted files) with snapshots
      - File type identification (by extension and magic bytes)
      - File metadata extraction (size, timestamps, permissions where available)
      - Binary-safe scanning and text extraction
      - Efficient handling of 1M+ files with indexing and pagination
      - Real-time change notifications surfaced into UI via WebSocket
    </file_monitoring>

    <content_analysis>
      - Text extraction across common document formats
      - Summarization and key-phrase extraction via Claude
      - Categorization with confidence scores
      - Automatic tag generation based on content and context
      - Duplicate and near-duplicate detection
      - Relationship mapping (files-to-files, files-to-conversations)
    </content_analysis>

    <scheduling>
      - Cron-like and calendar-style scheduling for scans and automations
      - Support for presets (hourly, daily, weekly, monthly) and custom cron strings
      - Timezone-aware scheduling with DST-safe logic
      - Pause/resume/cancel operations with audit logs
      - Resource throttling knobs (concurrency, IO caps)
      - Retry with exponential backoff and capped attempts
      - History view of schedule runs with metrics and outcomes
    </scheduling>

    <visualization_dashboard>
      - D3-based dashboards for scan coverage, tag distributions, trends
      - Relationship graphs linking files, tags, and conversations
      - Zoom/pan/hover interactions with performance targets (smooth at 60fps)
      - Export visuals to PNG/SVG/PDF formats
      - Configurable layouts (panels, saved views)
    </visualization_dashboard>

    <admin_audit_security>
      - RBAC-aware admin views (SYSOP/ADMIN only) for:
        - User and role management
        - System metrics
        - Audit log browsing and search
      - Comprehensive audit logging for all sensitive actions
      - Soft-delete patterns for key entities
    </admin_audit_security>
  </core_features>

  <key_interactions>
    <assistant_investigation_flow>
      1. User selects or creates a project (optional but recommended).
      2. User starts a new investigation session or resumes an existing one.
      3. User configures model and key parameters (temperature, tools) as needed.
      4. User types a prompt and sends.
      5. Backend streams assistant responses via SSE, UI renders progressively.
      6. Any detected artifacts appear in the side panel with preview.
      7. User may edit messages, regenerate responses, or branch the investigation session.
      8. All actions are logged for auditing.
    </assistant_investigation_flow>

    <file_scan_flow>
      1. Admin or authorized user configures root paths and filters.
      2. User defines one-off scan or schedule using scheduler UI.
      3. Scan is queued and executed by scanner service with progress updates.
      4. UI displays progress (files processed, estimated time, anomalies).
      5. Results (files, tags, relationships) feed into dashboards and search.
      6. Subsequent scans re-use checksums and change tracking for efficiency.
    </file_scan_flow>

    <artifact_flow>
      1. Claude response contains a code block or structured content.
      2. Application detects artifact and surfaces it in side panel.
      3. User opens artifact, views, and optionally edits it.
      4. User can re-prompt Claude using artifact content as context.
      5. User may download, copy, or full-screen the artifact.
      6. Version history and relevant audit events are recorded.
    </artifact_flow>

    <investigation_management_flow>
      1. User clicks "New Investigation" or selects a saved investigation session.
      2. Investigation auto-saves after the first assistant interaction.
      3. Titles auto-generate and may be edited inline.
      4. Investigation sessions can be pinned, archived, or moved into folders/projects.
      5. Search and filters help locate investigation sessions quickly.
      6. Actions update audit logs and respect RBAC.
    </investigation_management_flow>
  </key_interactions>

  <implementation_steps>
    <step number="1">
      <title>Project Foundation</title>
      <tasks>
        - Initialize monorepo with Bun and Spernakit template
        - Set up /frontend and /backend workspaces
        - Configure bunfig.toml and workspace scripts
        - Configure ESLint, Prettier, and TypeScript strict mode
        - Create config/spernakit.json and environment-specific variants
        - Initialize Prisma with SQLite database and base schema
        - Seed default RBAC roles and test users
      </tasks>
    </step>

    <step number="2">
      <title>Authentication, RBAC, and Security</title>
      <tasks>
        - Implement JWT-based auth with HTTP-only cookies
        - Implement 5-tier RBAC system with inheritance
        - Add ProtectedRoute components and RBAC-aware menus
        - Implement authorize() middleware in backend
        - Set up baseline audit logging service
        - Configure CORS, CSP, rate limiting, and validation
      </tasks>
    </step>

    <step number="3">
      <title>Core Database Schema</title>
      <tasks>
        - Model users, roles, projects, investigation sessions, messages, and artifacts
        - Model file entities, tags, relationships, and scan metadata
        - Model schedules, jobs, and job runs for the scheduler
        - Add audit fields and soft-delete patterns where required
        - Add strategic indexes for common queries
        - Generate migrations and run them via Bun scripts
      </tasks>
    </step>

    <step number="4">
      <title>Assistant Panel and Analysis Integration</title>
      <tasks>
        - Build assistant panel layout with sidebar + main panel for investigations over Heystack data
        - Implement SSE-based streaming response handling
        - Integrate Anthropic SDK behind backend proxy routes
        - Add markdown + code block rendering on frontend
        - Implement stop-generation, regenerate, and edit flows
        - Add model selection and advanced settings UI
      </tasks>
    </step>

    <step number="5">
      <title>Investigation Sessions and Projects</title>
      <tasks>
        - Implement CRUD for investigation sessions and folders/projects
        - Add sidebar with virtual scrolling and search
        - Implement pin, archive, and soft-delete
        - Implement project selector and project-scoped views
        - Add export functionality (JSON, Markdown, PDF skeleton)
      </tasks>
    </step>

    <step number="6">
      <title>Artifacts System</title>
      <tasks>
        - Detect artifact-worthy content in Claude responses
        - Implement artifact panel with tabs and previews
        - Add versioning and editing flows
        - Integrate Monaco-style code viewer and Mermaid renderer
        - Hook artifact actions into audit logging
      </tasks>
    </step>

    <step number="7">
      <title>Heystack File Scanner and Content Analysis</title>
      <tasks>
        - Implement scanner service and filesystem adapters
        - Integrate optional PowerShell bridge for Windows
        - Model scans, scan runs, and file metadata in Prisma
        - Implement content extraction and analysis pipeline
        - Store summaries, tags, relationships, and checksums
        - Ensure scanner performance and resilience (retries, resumption)
      </tasks>
    </step>

    <step number="8">
      <title>Scheduler and Automation</title>
      <tasks>
        - Implement scheduler engine with cron and calendar rules
        - Persist schedule definitions and runs
        - Expose scheduler APIs and admin UI
        - Wire scheduler to scanner and other automations
        - Add pause/resume/cancel and resource throttling controls
      </tasks>
    </step>

    <step number="9">
      <title>Dashboards and Visualizations</title>
      <tasks>
        - Build D3-based dashboards for key metrics
        - Implement relationship graphs with zoom/pan/hover
        - Add export of charts/graphs
        - Optimize visualizations for performance
      </tasks>
    </step>

    <step number="10">
      <title>Security, Observability, and Admin UX</title>
      <tasks>
        - Finalize audit logging and admin dashboards
        - Implement health, readiness, and liveness endpoints
        - Expose metrics endpoint for Prometheus
        - Add admin-only views for logs, metrics, and scans
        - Harden error handling and user-facing error messages
      </tasks>
    </step>

    <step number="11">
      <title>Polish, Testing, and Deployment</title>
      <tasks>
        - Implement full testing strategy (unit, integration, E2E, performance)
        - Polish UI for accessibility (WCAG 2.1 AA) and responsiveness
        - Optimize bundle sizes and load times
        - Build Docker image with nginx + supervisord
        - Configure production deployment, backups, and monitoring
      </tasks>
    </step>
  </implementation_steps>

  <success_criteria>
    <functionality>
      - Smooth SSE streaming for Heystack assistant responses related to file analysis, with a responsive UI
      - Accurate artifact detection and rendering
      - Reliable conversation/project management with soft delete
      - Correct RBAC enforcement across all key features
      - File scanning and analysis functioning at target scale
      - Scheduling system reliably executing jobs with retries
      - Dashboards and visualizations updating based on live data
    </functionality>

    <user_experience>
      - UI uses a familiar assistant-style layout inspired by modern tools while respecting Spernakit style and emphasizing file analysis workflows
      - Responsive layout across desktop, tablet, and mobile
      - Clear feedback for all user actions (loading, errors, confirmations)
      - Fast perceived performance, minimal visible blocking
      - Keyboard-accessible navigation and controls
    </user_experience>

    <technical_quality>
      - TypeScript strict mode passes with no errors
      - Lint and format checks pass with no violations
      - bun run build succeeds without warnings that indicate broken behavior
      - Database schema and queries validated under load
      - Error handling and logging present at all critical paths
    </technical_quality>

    <design_polish>
      - Consistent typography, spacing, and component usage
      - Fully functional dark mode with DaisyUI themes
      - Smooth micro-interactions and transitions
      - Accessible color contrast and focus states
    </design_polish>

    <security_compliance>
      - RBAC hierarchy enforced on backend and reflected in UI
      - All sensitive actions logged with sufficient context
      - Input validation and sanitization for all external inputs
      - Rate limiting active and observable on sensitive routes
      - Authentication implemented with HTTP-only cookies and secure defaults
      - Soft delete patterns applied where required
    </security_compliance>

    <file_management>
      - Scanning handles 1M+ files with acceptable performance
      - Change detection accurately tracks new/modified/deleted files
      - Checksums generated and stored for integrity and deduplication
      - Text extraction and categorization produce actionable results
      - Duplicate and relationship views behave correctly in UI
    </file_management>

    <scheduling_reliability>
      - Cron expressions parsed and executed as expected
      - Timezone handling validated over DST transitions
      - Resource limits respected under high load
      - Retry and backoff strategies verified via tests
      - Run history and metrics visible for operators
    </scheduling_reliability>

    <visualization_quality>
      - Charts and graphs render in &lt;= 200ms for 10,000 items
      - Graph layouts complete in &lt;= 1s for ~1,000 nodes
      - Interactions (zoom/pan/hover) remain smooth (~60fps)
      - Exported images/vectors are sharp and legible
    </visualization_quality>

    <performance_benchmarks>
      - API: 95% requests &lt;= 500ms; p99 within acceptable SLO
      - DB: 95% complex queries &lt;= 100ms
      - UI: initial page usable in &lt;= 200ms on modern hardware
      - Search: results for 1M files &lt;= 500ms (p95)
      - Concurrent users: stable for 50+ concurrent sessions
    </performance_benchmarks>
  </success_criteria>

  <spernakit_specific_optimizations>
    <performance>
      - Virtual scrolling for large lists (10,000+ conversations/files)
      - Strategic DB indexing for hot paths
      - Code splitting and lazy loading in Vite
      - Gzip/Brotli compression for text responses
      - Bundle optimization and tree-shaking
      - In-memory caching for frequently accessed data
    </performance>

    <file_management>
      - Incremental scanning with changed-only diffs
      - Efficient B-tree indexing on key file metadata fields
      - Resource-aware scanning with CPU/memory/IO caps
      - Background jobs for heavy content analysis
    </file_management>

    <observability>
      - Structured JSON logs with correlation IDs
      - Health, ready, and live endpoints for container orchestration
      - Metrics endpoint compatible with Prometheus
      - Real-time monitoring dashboards for admins
      - Threshold-based alerting for error rates and slowdowns
    </observability>

    <security>
      - 5-tier RBAC with inheritance and clear role definitions
      - Comprehensive audit trail covering core entities and actions
      - Input validation with shared schema definitions
      - CSP, CSRF protection (if applicable), secure cookies
      - Rate limiting with per-IP and per-endpoint rules
    </security>

    <development_workflow>
      - Single set of Bun scripts for lint/format/build/test
      - Shared TypeScript types for API contracts
      - Standardized error response format
      - Automated migrations as part of deploy pipeline
      - JSON-based configuration for all environments
    </development_workflow>

    <deployment_strategy>
      - Monolithic Docker container running nginx + supervisord
      - Only the frontend port (3330) exposed externally by default
      - Health and metrics endpoints wired into orchestrator probes
      - Persistent volume mounts for database and configuration
      - Environment-specific config via JSON files
    </deployment_strategy>

    <backup_recovery>
      - Regular SQLite backups with retention policies
      - Configuration versioning and rollback capability
      - Scan history retention with configurable window
      - Periodic integrity checks for database and key tables
    </backup_recovery>

    <compliance>
      - Considerations for GDPR/CCPA style data handling
      - Data retention policies configured per environment
      - Sensitive data masking in logs and analytics
      - Accessibility compliance targeting WCAG 2.1 AA
    </compliance>
  </spernakit_specific_optimizations>

  <integration_dependencies>
    <third_party_libraries>
      - D3.js v7
      - TanStack Query
      - React Router
      - DaisyUI + Tailwind CSS
      - Prisma ORM
      - Anthropic SDK
      - Joi/Zod (validation)
      - bcrypt (password hashing)
      - jsonwebtoken (JWT management)
    </third_party_libraries>

    <api_integrations>
      - Claude API via backend proxy
      - Native Node fs module for file operations
      - WebSockets for notifications and scan progress
      - SSE for streaming assistant/file-analysis responses
    </api_integrations>

    <fallback_mechanisms>
      - DB failures: retry with exponential backoff, graceful degradation
      - Claude API failures: retry and surface clear UX errors
      - Scan failures: partial scan resumption and queued re-runs
      - Network issues: queuing of non-critical operations for retry
    </fallback_mechanisms>
  </integration_dependencies>

  <quality_assurance>
    <testing_strategy>
      - Unit tests for business logic (90%+ coverage target)
      - Integration tests for API endpoints (85%+ coverage target)
      - E2E tests for critical user flows (assistant-driven investigations, projects, scans)
      - Performance and load tests for scanning and search
    </testing_strategy>

    <test_tools>
      - Vitest/Jest for unit + integration tests
      - Playwright for E2E
      - Pester (if needed) for PowerShell components
      - Custom load and stress test harnesses
    </test_tools>

    <bug_tracking>
      - Issue tracker with priority labels
      - Regression test suite maintained for critical issues
      - Error tracking via logs/metrics dashboards
    </bug_tracking>
  </quality_assurance>
</project_specification>
